# NOTE: This buildkite pipeline is saved in the WebUI

agents:
  queue: "julia"
  # Only run on `sandbox.jl` machines (not `docker`-isolated ones) since we need nestable sandboxing
  sandbox.jl: "true"
  os: "linux"
steps:
  - label: ":rocket: sync logs"
    plugins:
      - staticfloat/cryptic#v1:
          variables:
            - AWS_ACCESS_KEY_ID="U2FsdGVkX1/H9b08vYfGLIy0xYlKBA+pkT5XAjh5XrQdd5XNbjyVFXhv2XRsG13h"
            - AWS_SECRET_ACCESS_KEY="U2FsdGVkX1/YhdG5Jr9ywTjysCrjQIoAlfrVT8qMPzBoPttuG3NIMorn3LLcWpp657MEPhjib+MQ/At1qllwBg=="
          files:
            - ".buildkite/secrets/id_rsa"
      - staticfloat/ssh-agent:
          keyfiles:
            - .buildkite/secrets/id_rsa

      # Install Julia for sandbox
      - JuliaCI/julia#v1:
          version: "1.6"
          persist_depo_dirs: registries,packages,artifacts,compiled,scratchspaces
      - staticfloat/sandbox:
          rootfs_url: "https://github.com/JuliaCI/rootfs-images/releases/download/v3.14/pkgserver_logsync.x86_64.tar.gz"
          rootfs_treehash: "d2566c22a9bb357042e1135cf968e2c7fd32a54a"
          workspaces:
            - "$${BUILDKITE_PLUGIN_JULIA_CACHE_DIR}:$${BUILDKITE_PLUGIN_JULIA_CACHE_DIR}"
          verbose: "true"
    timeout_in_minutes: 240

    commands: |
      echo "--- Setup"
      LOG_DIR=$${JULIA_DEPOT_PATH}/scratchspaces/736c6f6f-5473-6973-796c-616e41676f4c/logs
      CSV_DIR=$${JULIA_DEPOT_PATH}/scratchspaces/736c6f6f-5473-6973-796c-616e41676f4c/csv_cache
      SANITIZED_CSV_DIR=$${JULIA_DEPOT_PATH}/scratchspaces/736c6f6f-5473-6973-796c-616e41676f4c/sanitized_csvs
      mkdir -p "$${LOG_DIR}"
      
      # Get list of servers
      SERVERS=( $$(curl -sfL https://pkg.julialang.org/meta/siblings | jq -r '.[]') )

      # Instantiate our project
      julia --project -e 'import Pkg; Pkg.instantiate()'

      echo "+++ Downloading logs from $${#SERVERS[@]} servers"
      for IDX in $${!SERVERS[@]}; do
        SERVER="$$(curl -sfL "$${SERVERS[$${IDX}]}/meta" | jq -r '.pkgserver_url' | sed -e 's&^https://&&')" || true
        if [[ -z "$${SERVER}" ]]; then
          buildkite-agent annotate --style error "Server $${SERVERS[$${IDX}]} could not self-identify!"
          continue
        fi
        echo " -> [$$IDX/$${#SERVERS[@]}] $${SERVER}"

        USER=ubuntu
        if [[ "$${SERVER}" == cn-* ]]; then
          USER=centos
        fi
        # Ignore return code from `rsync` so that we can skip failing servers
        # Also limit each transfer to 120s, so that we don't end up eating huge amounts of
        # CI time if a chinese server is feeling particularly slow today
        (timeout 120s rsync -Prt -e "ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -oBatchMode=yes" \
                      "$${USER}@$${SERVER}:~/src/PkgServer.jl/deployment/logs/nginx/access_*.gz" \
                      "$${LOG_DIR}" || true) &
      done

      # Wait for all those `rsync` commands to finish
      wait

      echo "+++ Uploading raw (gzip-compressed) logs to S3 (these expire after 30 days)"
      aws s3 sync --acl=private "$${LOG_DIR}" "s3://julialang-pkgserver-logs/raw/"

      echo "--- Checking which logfiles need to be parsed"
      function s3_csv_zst_exists() {
        aws s3api head-object --bucket julialang-logs --key pkgservers/csv/$$1 >/dev/null 2>/dev/null
      }

      LOGS_TO_PARSE=()
      CSVS_TO_SANITIZE=()
      for f in $${LOG_DIR}/*.gz; do
        csv_zst_name="$$(basename $${f%.*}).csv.zst"
        if ! s3_csv_zst_exists "$${csv_zst_name}"; then
          LOGS_TO_PARSE+=( "$${f}" )
          CSVS_TO_SANITIZE+=( "$${CSV_DIR}/$${csv_zst_name}" )
          echo -n "!"
        else
          echo -n "."
        fi
      done
      echo

      echo "+++ Parsing $${#LOGS_TO_PARSE[@]} logfiles"
      julia --project bin/parse_logfiles.jl "$${LOGS_TO_PARSE[@]}"

      echo "+++ Sanitizing newly-created CSVs"
      julia --project bin/sanitize_csvs.jl "$${SANITIZED_CSV_DIR}" "$${CSVS_TO_SANITIZE[@]}"

      echo "+++ Uploading '.csv.zst' files to S3"
      for f in "$${LOGS_TO_PARSE[@]}"; do
        csv_zst_name="$$(basename $${f%.*}).csv.zst"

        # Upload raw `.csv.zst` file; this gets deleted after 30 days
        aws s3 cp --acl=private "$${CSV_DIR}/$${csv_zst_name}" "s3://julialang-pkgserver-logs/csv/$${csv_zst_name}"

        # Upload sanitized `.csv.zst` file; this stays forever
        aws s3 cp --acl=private "$${SANITIZED_CSV_DIR}/$${csv_zst_name}" "s3://julialang-pkgserver-logs-sanitized/csv/$${csv_zst_name}"
      done
